{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead0943d",
   "metadata": {},
   "source": [
    "# Parte - 1 Introdução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d154d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "Collecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853646 sha256=f732e2a652949f286af29a883b5ac820396278aecf97c2fa936bad7f779c68c0\n",
      "  Stored in directory: c:\\users\\feoxp7\\appdata\\local\\pip\\cache\\wheels\\52\\45\\50\\69db7b6e1da74a1b9fcc097827db9185cb8627117de852731e\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\feoxp7\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\feoxp7\\appdata\\local\\pip\\cache\\wheels\\52\\45\\50\\69db7b6e1da74a1b9fcc097827db9185cb8627117de852731e\\pyspark-3.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: py4j==0.10.9.3 in c:\\users\\feoxp7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyspark) (0.10.9.3)\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\feoxp7\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7269c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b9a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leticia</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marisa</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paulo</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age\n",
       "0  Leonardo   29\n",
       "1   Leticia   26\n",
       "2    Marisa   54\n",
       "3     Paulo   56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4034938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PL1BRSSU0250NB.net.plm.eds.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practica</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2ae910b8af0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practica').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e5b04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|     _c0|_c1|       _c2|\n",
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('data.csv', sep=';')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa04d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header', 'true').csv('data.csv', sep=';').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8bdd9ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30487826",
   "metadata": {},
   "source": [
    "# Parte 2 - DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105eeb6",
   "metadata": {},
   "source": [
    "* Pyspark Dataframe\n",
    "* Lendo o dataset\n",
    "* Verificando datatypes das colunas (Schema)\n",
    "* Selecionando Colunas e indexação\n",
    "* Check Describe option similar to Pandas\n",
    "* Adicionando Colunas\n",
    "* Dropando Colunas\n",
    "* Renomeando Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19062c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PL1BRSSU0250NB.net.plm.eds.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practica</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2ae910b8af0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practica - DataFrame').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "439e9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lendo o dataset \n",
    "df_spark = spark.read.option('header', 'true').csv('data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4834ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c8e0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veja que todas as informações foram tratadas como strings. Até mesmo a idade. \n",
    "#Para corrigir isso, usamos o parametro inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a98bef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Lendo o dataset \n",
    "df_spark = spark.read.option('header', 'true').csv('data.csv', sep=';', inferSchema=True)\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f54aab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('data.csv', sep=';', header=True, inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f01bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificando o schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dff0f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n",
      "+---+--------+\n",
      "|Age|    Name|\n",
      "+---+--------+\n",
      "| 29|Leonardo|\n",
      "| 56|   Paulo|\n",
      "| 54|  Marisa|\n",
      "| 26| Leticia|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selecting Columns \n",
    "df_spark.select('Age', 'Name').printSchema()\n",
    "df_spark.select('Age', 'Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31b27472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f9beeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6ad656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+----------+\n",
      "|summary|    Name|               Age|Experience|\n",
      "+-------+--------+------------------+----------+\n",
      "|  count|       4|                 4|         4|\n",
      "|   mean|    null|             41.25|       5.0|\n",
      "| stddev|    null|15.945218719101975|       0.0|\n",
      "|    min|Leonardo|                26|         5|\n",
      "|    max|   Paulo|                56|         5|\n",
      "+-------+--------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algumas informações importantes\n",
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3766eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------------------+\n",
      "|    Name|Age|Experience|Experience After 2 Year|\n",
      "+--------+---+----------+-----------------------+\n",
      "|Leonardo| 29|         5|                      7|\n",
      "|   Paulo| 56|         5|                      7|\n",
      "|  Marisa| 54|         5|                      7|\n",
      "| Leticia| 26|         5|                      7|\n",
      "+--------+---+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adicionando colunas em um dataframe \n",
    "df_spark.withColumn('Experience After 2 Year', df_spark['Experience']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b43cab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Removendo colunas\n",
    "df_spark = df_spark.drop('Experience After 2 Year')\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dfac4d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|New Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Renomeando colunas \n",
    "df_spark.withColumnRenamed('Name','New Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ac4aa",
   "metadata": {},
   "source": [
    "#  Parte 3 - Lidando com valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c541fa",
   "metadata": {},
   "source": [
    "* Dropando Colunas\n",
    "* Dropando Linhas \n",
    "* Vários parâmetros em drop funcionalidades\n",
    "* Lidando com valores ausentes com média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36beb0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PL1BRSSU0250NB.net.plm.eds.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practica</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2ae910b8af0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practica - DataFrame').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7189c5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+\n",
      "|    Name| Age|Experience|\n",
      "+--------+----+----------+\n",
      "|Leonardo|  29|         5|\n",
      "|   Paulo|  56|         5|\n",
      "|  Marisa|  54|         5|\n",
      "| Leticia|  26|         5|\n",
      "|   Heron|null|         4|\n",
      "| Pitucha|  25|      null|\n",
      "|    null|  35|      null|\n",
      "+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Lendo o dataset \n",
    "df_spark = spark.read.option('header', 'true').csv('data2.csv', sep=';', inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "57724bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|    Name| Age|\n",
      "+--------+----+\n",
      "|Leonardo|  29|\n",
      "|   Paulo|  56|\n",
      "|  Marisa|  54|\n",
      "| Leticia|  26|\n",
      "|   Heron|null|\n",
      "| Pitucha|  25|\n",
      "|    null|  35|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop a coluna\n",
    "df_spark.drop('Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfc22988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f8a4a04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+\n",
      "|    Name| Age|Experience|\n",
      "+--------+----+----------+\n",
      "|Leonardo|  29|         5|\n",
      "|   Paulo|  56|         5|\n",
      "|  Marisa|  54|         5|\n",
      "| Leticia|  26|         5|\n",
      "|   Heron|null|         4|\n",
      "| Pitucha|  25|      null|\n",
      "|    null|  35|      null|\n",
      "+--------+----+----------+\n",
      "\n",
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|Leonardo| 29|         5|\n",
      "|   Paulo| 56|         5|\n",
      "|  Marisa| 54|         5|\n",
      "| Leticia| 26|         5|\n",
      "+--------+---+----------+\n",
      "\n",
      "+--------+----+----------+\n",
      "|    Name| Age|Experience|\n",
      "+--------+----+----------+\n",
      "|Leonardo|  29|         5|\n",
      "|   Paulo|  56|         5|\n",
      "|  Marisa|  54|         5|\n",
      "| Leticia|  26|         5|\n",
      "|   Heron|null|         4|\n",
      "| Pitucha|  25|      null|\n",
      "|    null|  35|      null|\n",
      "+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop linhas que tenho null values em todos os campos\n",
    "df_spark.na.drop(how=\"all\").show()\n",
    "\n",
    "#Drop linhas que tenho null values em pelo menos um campo\n",
    "df_spark.na.drop(how=\"any\").show()\n",
    "\n",
    "#Drop linhas que tenho null values em + de 1 campo (o 1 é definido pelo parametro thresh)\n",
    "df_spark.na.drop(how=\"any\", thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6a475b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+\n",
      "|    Name| Age|Experience|\n",
      "+--------+----+----------+\n",
      "|Leonardo|  29|         5|\n",
      "|   Paulo|  56|         5|\n",
      "|  Marisa|  54|         5|\n",
      "| Leticia|  26|         5|\n",
      "|   Heron|null|         4|\n",
      "+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SubSet - Dropa linhas se algum valor de uma coluna especifica estiver como null\n",
    "df_spark.na.drop(how=\"any\", subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eebdf609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+----------+\n",
      "|         Name| Age|Experience|\n",
      "+-------------+----+----------+\n",
      "|     Leonardo|  29|         5|\n",
      "|        Paulo|  56|         5|\n",
      "|       Marisa|  54|         5|\n",
      "|      Leticia|  26|         5|\n",
      "|        Heron|null|         4|\n",
      "|      Pitucha|  25|      null|\n",
      "|Missing Value|  35|      null|\n",
      "+-------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the Missing Value\n",
    "df_spark.na.fill('Missing Value').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f42c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preenchendo valores com algumas estratégias\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(\n",
    "    inputCols = ['Age', 'Experience'],\n",
    "    outputCols = [\"{}_imputed\".format(c) for c in ['Age', 'Experience']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e3d794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+------------------+\n",
      "|    Name| Age|Experience|Age_imputed|Experience_imputed|\n",
      "+--------+----+----------+-----------+------------------+\n",
      "|Leonardo|  29|         5|         29|                 5|\n",
      "|   Paulo|  56|         5|         56|                 5|\n",
      "|  Marisa|  54|         5|         54|                 5|\n",
      "| Leticia|  26|         5|         26|                 5|\n",
      "|   Heron|null|         4|         37|                 4|\n",
      "| Pitucha|  25|      null|         25|                 4|\n",
      "|    null|  35|      null|         35|                 4|\n",
      "+--------+----+----------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add imputation cols to df \n",
    "imputer.fit(df_spark).transform(df_spark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc4849",
   "metadata": {},
   "source": [
    "#  Parte 4 - Operações com Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1edfd",
   "metadata": {},
   "source": [
    "* &, |, ==\n",
    "* ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3b347f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PL1BRSSU0250NB.net.plm.eds.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practica</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2ae910b8af0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practica - DataFrame').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a11f6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Lendo o dataset \n",
    "df_spark = spark.read.option('header', 'true').csv('data3.csv', sep=';', inferSchema=True)\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f1d553e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Marisa| 54|         5|  5200|\n",
      "|Leticia| 26|         5| 15000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Salario das pessoas igual ou maior que 5000\n",
    "df_spark.filter(\"Salary>5000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ccf6f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|Marisa| 54|         5|  5200|\n",
      "+------+---+----------+------+\n",
      "\n",
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|Leonardo| 29|         5|  4000|\n",
      "|   Paulo| 56|         5|  5000|\n",
      "|  Marisa| 54|         5|  5200|\n",
      "| Leticia| 26|         5| 15000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.filter((df_spark['Salary']>5000) & (df_spark['Salary']<15000)).show()\n",
    "df_spark.filter((df_spark['Salary']>5000) | (df_spark['Salary']<15000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a781c3c",
   "metadata": {},
   "source": [
    "#  Parte 5 - Group By e funções de agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45667506",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practica - DataFrame').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2a1aac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departament: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Lendo o dataset \n",
    "df = spark.read.option('header', 'true').csv('data4.csv', sep=';', inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "76a6d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------+\n",
      "|    Name| Departament|Salary|\n",
      "+--------+------------+------+\n",
      "|Leonardo|Data Science| 10000|\n",
      "|   Paulo|         IOT|  5000|\n",
      "|  Marisa|    Big Data|  4000|\n",
      "| Leticia|    Big Data|  4000|\n",
      "|   Bruno|Data Science|  3000|\n",
      "|   Pedro|Data Science| 10000|\n",
      "|Caroline|         IOT|  5000|\n",
      "+--------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71bc290e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, sum(Salary): bigint]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GroupBy\n",
    "df.groupBy('Name').sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
